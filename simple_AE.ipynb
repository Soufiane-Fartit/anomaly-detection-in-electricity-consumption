{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named read_nilmtk",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4cd61c0457e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mread_nilmtk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named read_nilmtk"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Activation, Lambda, MaxPooling1D\n",
    "from keras.losses import mse, binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD, adam, RMSprop, Nadam, Adadelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from read_nilmtk import read_data\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage.filters as filters\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shallow(optimizer='Nadam', loss='categorical_crossentropy', mid_activation='sigmoid', out_activation='sigmoid'):\n",
    "    \n",
    "    input_window = Input(shape=(window_length,))\n",
    "    \n",
    "\n",
    "    encoded = Dense(latent_size, activation=mid_activation)(input_window)\n",
    "    \n",
    "    decoded = Dense(window_length, activation=out_activation)(encoded)\n",
    "\n",
    "    encoder = Model(input_window, encoded)\n",
    "    autoencoder = Model(input_window, decoded)\n",
    "\n",
    "    autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_train_shifted_8, x_test_shifted_8, v_train, v_test  = read_data(1,'microwave',1)\n",
    "x_train = np.squeeze(x_train, axis=2)\n",
    "x_test = np.squeeze(x_test, axis=2)\n",
    "x_train_shifted_8 = np.squeeze(x_train_shifted_8, axis=2)\n",
    "x_test_shifted_8 = np.squeeze(x_test_shifted_8, axis=2)\n",
    "v_train = np.squeeze(v_train, axis=2)\n",
    "v_test = np.squeeze(v_test, axis=2)\n",
    "\n",
    "\n",
    "#train_set = np.concatenate((x_train,x_train_shifted_8), axis=0)\n",
    "train_set = x_train\n",
    "test_set = x_test\n",
    "pos_shifted_train_set = x_train_shifted_8\n",
    "pos_shifted_set = x_test_shifted_8\n",
    "neg_shifted_set = v_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 2\n",
    "window_length=24\n",
    "optimizer='Nadam'\n",
    "loss='categorical_crossentropy'\n",
    "mid_activation='sigmoid'\n",
    "out_activation='sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = shallow()\n",
    "autoencoder.fit(train_set, train_set, batch_size=32,\n",
    "                epochs=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the latent space of the AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train = encoder.predict(train_set)\n",
    "latent_shifted_train = encoder.predict(pos_shifted_train_set)\n",
    "latent_test = encoder.predict(test_set)\n",
    "latent_shifted_pos = encoder.predict(pos_shifted_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latent_size == 2:\n",
    "    X,Y = latent_test.T\n",
    "    XN,YN = latent_shifted_pos.T\n",
    "    #XNN,YNN = latent_shifted_neg.T\n",
    "    plt.plot(X, Y, 'go')\n",
    "    plt.plot(XN, YN, 'ro')\n",
    "    #plt.plot(XNN, YNN, 'yo')\n",
    "elif latent_size ==3:\n",
    "    from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "    data = (latent_test, latent_shifted_pos,latent_shifted_neg)\n",
    "    colors = (\"green\", \"red\", \"yellow\")\n",
    "    groups = (\"normal\", \"anomaly\", \"anomaly\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "    #X,Y,Z = latent_test.T\n",
    "    #XN,YN,ZN = latent_shifted_pos.T\n",
    "    for data, color, group in zip(data, colors, groups):\n",
    "        x, y, z = data.T\n",
    "        ax.scatter(x, y, z, alpha=0.8, c=color, edgecolors='none', s=30, label=group)\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare latent data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_preprocess(latent_test, latent_ran_test):\n",
    "\tL = []\n",
    "\tlen(L)\n",
    "\tfor x in latent_test:\n",
    "\t\tL.append([x,0])\n",
    "\tfor x in latent_ran_test:\n",
    "\t\tL.append([x,1])\n",
    "\n",
    "\tL = np.array(L)\n",
    "\tnp.random.shuffle(L)\n",
    "\tL.shape\n",
    "\tL[0]\n",
    "\tL[1]\n",
    "\n",
    "\tinputs = [x[0] for x in L]\n",
    "\ttargets = [x[1] for x in L]\n",
    "\n",
    "\treturn inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "features_matrix_train, labels_train = class_preprocess(latent_train, latent_shifted_train)\n",
    "\n",
    "#test\n",
    "features_matrix_test, labels_test = class_preprocess(latent_test, latent_shifted_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the random forest classifier\n",
    "classifier = RandomForestClassifier(bootstrap= True, min_samples_leaf = 5, n_estimators = 1000, min_samples_split = 8, max_features = 2, max_depth = 80)\n",
    "classifier.fit(features_matrix_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and evaluate\n",
    "predicted_labels_test = classifier.predict(np.array(features_matrix_test))\n",
    "\n",
    "print(confusion_matrix(labels_test,predicted_labels_test))\n",
    "print(classification_report(labels_test,predicted_labels_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
