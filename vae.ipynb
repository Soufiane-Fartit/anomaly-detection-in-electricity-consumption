{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import LSTM, Dense, RepeatVector, Subtract, Add, TimeDistributed, UpSampling1D, Embedding, Flatten, BatchNormalization, Activation, Lambda, Conv1D, MaxPooling1D\n",
    "from keras.losses import mse, binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD, adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from read_nilmtk import read_data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def class_preprocess(latent_test, latent_ran_test):\n",
    "\tL = []\n",
    "\tlen(L)\n",
    "\tfor x in latent_test:\n",
    "\t\tL.append([x,0])\n",
    "\tfor x in latent_ran_test:\n",
    "\t\tL.append([x,1])\n",
    "\n",
    "\tL = np.array(L)\n",
    "\tnp.random.shuffle(L)\n",
    "\tL.shape\n",
    "\tL[0]\n",
    "\tL[1]\n",
    "\n",
    "\tinputs = [x[0] for x in L]\n",
    "\ttargets = [x[1] for x in L]\n",
    "\n",
    "\treturn inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_train_shifted_8, x_test_shifted_8, v_train, v_test  = read_data(1,'kettle',1)\n",
    "x_train = np.squeeze(x_train, axis=2)\n",
    "x_test = np.squeeze(x_test, axis=2)\n",
    "x_train_shifted_8 = np.squeeze(x_train_shifted_8, axis=2)\n",
    "x_test_shifted_8 = np.squeeze(x_test_shifted_8, axis=2)\n",
    "v_train = np.squeeze(v_train, axis=2)\n",
    "v_test = np.squeeze(v_test, axis=2)\n",
    "\n",
    "#train_set = np.concatenate((x_train,x_train_shifted_8), axis=0)\n",
    "train_set = x_train\n",
    "test_set = x_test\n",
    "pos_shifted_train_set = x_train_shifted_8\n",
    "pos_shifted_set = x_test_shifted_8\n",
    "neg_shifted_set = v_test\n",
    "\n",
    "features_matrix_train, labels_train = class_preprocess(x_train, x_train_shifted_8)\n",
    "features_matrix_train = np.array(features_matrix_train)\n",
    "labels_train = np.array(labels_train)\n",
    "features_matrix_test, labels_test = class_preprocess(x_test, x_test_shifted_8)\n",
    "features_matrix_test = np.array(features_matrix_test)\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_shallow(optimizer='Nadam', mid_activation='linear', out_activation='sigmoid', kl_coef=1):\n",
    "    \n",
    "    def my_vae_loss(y_true, y_pred):\n",
    "        reconstruction_loss = 24*categorical_crossentropy(y_true, y_pred)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - 0.001*K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "\n",
    "        vae_loss = K.mean(reconstruction_loss + kl_coef*kl_loss)\n",
    "        return vae_loss\n",
    "\n",
    "\n",
    "    input_window = Input(shape=(window_length,))\n",
    "\n",
    "    z_mean = Dense(latent_size, name='z_mean', activation=mid_activation)(input_window)\n",
    "    z_log_var = Dense(latent_size, name='z_log_var', activation=mid_activation)(input_window)\n",
    "    \n",
    "    z = Lambda(sampling, output_shape=(latent_size,), name='z')([z_mean, z_log_var])\n",
    "    z = Activation('sigmoid')(z)\n",
    "\n",
    "    decoded = Dense(window_length, activation=out_activation)(z)\n",
    "\n",
    "    encoder = Model(input_window, [z_mean, z_log_var, z])\n",
    "    autoencoder = Model(input_window, decoded)\n",
    "\n",
    "    autoencoder.compile(optimizer=optimizer, loss=my_vae_loss)\n",
    "    \n",
    "    return autoencoder, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 2\n",
    "window_length=24\n",
    "optimizer='Nadam'\n",
    "mid_activation='sigmoid'\n",
    "out_activation='sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = var_shallow()\n",
    "history = autoencoder.fit(train_set, train_set,\n",
    "                epochs=200,\n",
    "                batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mean and var latent spaces of the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train = encoder.predict(train_set)\n",
    "latent_shifted_train = encoder.predict(pos_shifted_train_set)\n",
    "latent_test = encoder.predict(test_set)\n",
    "latent_shifted_pos = encoder.predict(pos_shifted_set)\n",
    "\n",
    "#extract means\n",
    "mean_train = latent_train[0]\n",
    "mean_shifted_train = latent_shifted_train[0]\n",
    "mean_test = latent_test[0]\n",
    "mean_shifted_pos = latent_shifted_pos[0]\n",
    "\n",
    "#extract vars\n",
    "var_train = latent_train[1]\n",
    "var_shifted_train = latent_shifted_train[1]\n",
    "var_test = latent_test[1]\n",
    "var_shifted_pos = latent_shifted_pos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearange it into a 4-dim vectors to be fed to the classifier\n",
    "\n",
    "x,y = mean_train.T\n",
    "w,z = var_train.T\n",
    "c = zip(x,y,w,z)\n",
    "latent_train = np.array(c)\n",
    "\n",
    "x,y = mean_shifted_train.T\n",
    "w,z = var_shifted_train.T\n",
    "c = zip(x,y,w,z)\n",
    "latent_shifted_train = np.array(c)\n",
    "\n",
    "x,y = mean_test.T\n",
    "w,z = var_test.T\n",
    "c = zip(x,y,w,z)\n",
    "latent_test = np.array(c)\n",
    "\n",
    "x,y = mean_shifted_pos.T\n",
    "w,z = var_shifted_pos.T\n",
    "c = zip(x,y,w,z)\n",
    "latent_shifted_pos = np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the latent spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latent_size == 2:\n",
    "    X,Y,W,Z = latent_test.T\n",
    "    XN,YN,WN,ZN = latent_shifted_pos.T\n",
    "    #XNN,YNN = latent_shifted_neg.T\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(X, Y, 'go')\n",
    "    plt.plot(XN, YN, 'ro')\n",
    "    plt.title('Means')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(W, Z, 'go')\n",
    "    plt.plot(WN, ZN, 'ro')\n",
    "    plt.title('Variability')\n",
    "    #plt.plot(XNN, YNN, 'yo')\n",
    "elif latent_size ==3:\n",
    "    from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "    data = (latent_test, latent_shifted_pos,latent_shifted_neg)\n",
    "    colors = (\"green\", \"red\", \"yellow\")\n",
    "    groups = (\"normal\", \"anomaly\", \"anomaly\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "    #X,Y,Z = latent_test.T\n",
    "    #XN,YN,ZN = latent_shifted_pos.T\n",
    "    for data, color, group in zip(data, colors, groups):\n",
    "        x, y, z = data.T\n",
    "        ax.scatter(x, y, z, alpha=0.8, c=color, edgecolors='none', s=30, label=group)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare latent data for classification\n",
    "#train\n",
    "features_matrix_train, labels_train = class_preprocess(latent_train, latent_shifted_train)\n",
    "#test\n",
    "features_matrix_test, labels_test = class_preprocess(latent_test, latent_shifted_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the classifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(features_matrix_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and evaluate\n",
    "predicted_labels_test = classifier.predict(np.array(features_matrix_test))\n",
    "print(confusion_matrix(labels_test,predicted_labels_test))\n",
    "print(classification_report(labels_test,predicted_labels_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
